services:
  # Kafka with KRaft (no Zookeeper needed) - MEMORY OPTIMIZED
  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      # CRITICAL: Reduced memory allocation for t2.micro
      KAFKA_HEAP_OPTS: "-Xmx200M -Xms100M"
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,CONTROLLER://0.0.0.0:29093,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:29093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      # Reduced retention for less disk usage
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_LOG_RETENTION_BYTES: 104857600
      KAFKA_LOG_SEGMENT_BYTES: 52428800
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
    networks:
      - event-network
    # Resource limits for t2.micro
    deploy:
      resources:
        limits:
          memory: 300M
        reservations:
          memory: 150M
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s

  # MongoDB - MEMORY OPTIMIZED
  mongodb:
    image: mongo:7
    container_name: mongodb
    ports:
      - "27017:27017"
    # Reduced cache size for t2.micro
    command: --wiredTigerCacheSizeGB 0.25
    volumes:
      - mongodb_data:/data/db
    networks:
      - event-network
    # Resource limits
    deploy:
      resources:
        limits:
          memory: 300M
        reservations:
          memory: 150M
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Our Application - OPTIMIZED
  app:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: event-microservice
    ports:
      - "3000:3000"
    depends_on:
      kafka:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    environment:
      PORT: 3000
      NODE_ENV: production
      MONGODB_URI: mongodb://mongodb:27017/event-microservice
      KAFKA_BROKERS: kafka:29092
      KAFKA_CLIENT_ID: event-microservice
      KAFKA_GROUP_ID: activity-consumer-group
      KAFKA_TOPIC: user-activities
      # Node.js memory limit
      NODE_OPTIONS: "--max-old-space-size=200"
    networks:
      - event-network
    restart: unless-stopped
    # Resource limits
    deploy:
      resources:
        limits:
          memory: 250M
        reservations:
          memory: 100M
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 40s

networks:
  event-network:
    driver: bridge

volumes:
  mongodb_data:
    driver: local